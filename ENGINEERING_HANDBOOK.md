# Технічна Конституція та Архітектурний Фундамент Стартапу (Редакція 2025 року)

## Операціоналізація (Enforcement)

Цей документ має юридичну силу всередині репозиторію і виконується автоматично.

### Автоматичні гейти
- **Conventional Commits**: PR title та коміти відповідають формату Conventional Commits.
- PR titles must be Conventional Commits: type: subject.
- **Trunk-based**: PR тільки в `main`.
- **Lint + Tests + Coverage**: лінт, unit tests і coverage-пороги блокують злиття.
- **Metrics**: зміни в метриках вимагають оновлених тестів і бенчмарків.
- **ML/CV**: моделі лише через DVC + обов'язкові model cards та benchmark logs
  (UI-фасад CV живе у `lib/services/ui/`).
- **Privacy**: заборонена персистенція raw video; зберігаються лише скелет/landmarks.
- **Architecture**: чиста архітектура — domain без framework imports.
- **Bidi safety**: заборонені bidi/Unicode control characters у вихідниках;
  перед комітом перевіряйте `rg -n --pcre2 '[\\u202A-\\u202E\\u2066-\\u2069]'`.

### Обов'язкові артефакти
- `docs/` — документація як гейт для metrics/ML/architecture.
- `ml-ops/model_cards/` — картки моделей.
- `ml-ops/benchmarks/` — логи бенчмарків.

## 1. Вступ: Інженерна Доктрина та Філософія Продукту

### 1.1 Мета та Стратегічний Контекст
Цей документ слугує фундаментальною інженерною директивою для створення нового GitHub-орієнтованого стартапу. Це не просто технічна специфікація, а кодифікація інженерного етосу, необхідного для побудови високоефективного, масштабованого та домінуючого на ринку мобільного AI-продукту в умовах технологічного ландшафту 2025 року. Мета полягає у створенні "фундаменту класу SpaceX" — репозиторію, що характеризується екстремальною надійністю, швидкістю ітерацій, мисленням від перших принципів та агресивною оптимізацією.

Запропонована архітектура інтегрує передові (State-of-the-Art, SOTA) конвеєри комп'ютерного зору (Computer Vision, CV), з особливим фокусом на оцінці пози людини (Human Pose Estimation, HPE) та машинному навчанні на пристрої (On-Device ML). Ця система оркеструється в межах надійного середовища Mobile MLOps. Цей звіт визначає інженерні стандарти, вибір платформ, архітектурні патерни та структуру репозиторію, необхідні для підтримки траєкторії гіперзростання стартапу.

### 1.2 Інженерна Культура: "Алгоритм"
Приймаючи інженерну філософію, популяризовану SpaceX та секторами високоефективного виробництва, цей проект буде дотримуватися "Алгоритму" як основного процесу розробки. Цей підхід є критичним для запобігання "роздуванню" (bloat), яке вражає сучасні програмні стартапи. Ми відмовляємося від корпоративних анти-патернів на користь прямої, фізично обґрунтованої інженерії.

- **Ставте під сумнів кожну вимогу:** Жодна вимога не є "дурною", але вимоги від "розумних" людей (або стандартні галузеві практики) є найнебезпечнішими. Кожна функція, бібліотека та архітектурний шар повинні бути суворо обґрунтовані фізикою та першими принципами, а не конвенціями. Якщо вимога не має прізвища відповідального інженера, вона не існує.
- **Видаліть частину або процес:** Мета не в тому, щоб оптимізувати компонент, який не повинен існувати. Ми надаємо пріоритет видаленню непотрібних шарів (наприклад, зайвих обгорток, надлишкових перетворень даних) над їх оптимізацією. Якщо ми не змушені повертати частину назад у 10% випадків, ми видаляємо недостатньо агресивно.
- **Спростіть та оптимізуйте:** Тільки після кроку 2 ми оптимізуємо. Поширеною помилкою є оптимізація обмеження, якого не повинно існувати. У мобільному ML це означає переконатися, що ми не оптимізуємо виклик хмарного API, коли виведення (inference) має відбуватися на пристрої.
- **Прискорюйте час циклу:** Швидкість конвеєра CI/CD репозиторію визначає швидкість інновацій. Якщо збірка займає 20 хвилин, цикл ітерації зламаний.
- **Автоматизуйте:** Ручне тестування та розгортання заборонені. Якщо процес відбувається двічі, він повинен бути заскриптований.

### 1.3 Модель "Відповідального Інженера" (Responsible Engineer - RE)
У цьому репозиторії буде примусово впроваджено концепцію "Відповідального Інженера". На відміну від традиційних схем, де системні інженери пишуть вимоги, а розробники їх виконують, RE повністю володіє компонентом — від критеріїв проектування до розгортання та моніторингу телеметрії. RE діє як поєднання інженера-дослідника, системного архітектора та головного інженера для свого модуля.

Структура репозиторію відображатиме цю власність через чіткі розмежування можливостей коду (CODEOWNERS) та модульну архітектуру, що дозволяє незалежну перевірену ітерацію.

Інженери не є "гвинтиками", що виконують таски з Jira. Вони є власниками підсистем. Якщо підсистема дає збій у продакшені, RE відповідає за виправлення. Це стимулює написання надійного коду та глибоке розуміння системи.

## 2. Стратегічний Аналіз Платформ та Обладнання (Ландшафт 2025 року)

### 2.1 Імператив Edge-First (Штучний Інтелект на Межі)
До 2025 року парадигма мобільного AI рішуче змістилася від хмарного виведення до "Edge AI". Сучасні флагманські системи на кристалі (SoC), такі як Qualcomm Snapdragon 8 Gen 4 та Apple A18 Pro, оснащені нейронними процесорами (NPU), здатними виконувати понад 50-70 трильйонів операцій за секунду (TOPS). Це перевищує можливості багатьох дискретних відеокарт минулих поколінь для задач інференсу.

**Стратегічне Рішення: Стартап прийме стратегію Offline-First, On-Device AI.**

Це рішення базується на фізичних обмеженнях та економічній доцільності:

- **Латентність (Latency):** Хмарне виведення вносить змінну затримку (50мс - 2000мс) через мережеві умови, що є неприйнятним для корекції пози в реальному часі або спортивної аналітики, де зворотний зв'язок має бути миттєвим. Інференс на пристрої гарантує стабільну затримку менше 16мс (60 FPS), забезпечуючи плавність інтерфейсу "Tesla-класу".
- **Приватність (Privacy):** Обробка біометричних даних (скелет/обличчя) безпосередньо на пристрої усуває необхідність передачі чутливих відеопотоків у хмару. Це кардинально зменшує накладні витрати на відповідність GDPR та ризики витоку даних, роблячи продукт безпечним за дизайном (Privacy by Design).
- **Економіка (Unit Economics):** Перенесення обчислень на пристрої користувачів знижує витрати на хмарні GPU практично до нуля. Це дозволяє стартапу масштабуватися до мільйонів користувачів без лінійного зростання витрат на інфраструктуру, що є критичним для виживання та маржинальності.

### 2.2 Вибір Операційної Системи: Аргументація Нативної Розробки
Хоча крос-платформні фреймворки, такі як Flutter та React Native, є популярними для загальних додатків, високопродуктивний комп'ютерний зір вимагає прямого доступу до апаратних буферів та делегатів GPU/NPU.

**Аналіз варіантів:**

- **React Native:** Покладається на міст (bridge) або JSI (JavaScript Interface) для комунікації з нативними модулями. Хоча бібліотеки на кшталт VisionCamera дозволяють використовувати "Frame Processors" на C++, шар абстракції додає складності при налагодженні низькорівневих витоків пам'яті в тензорних операціях. Передача великих обсягів даних через JSI може створювати "вузькі місця".
- **Flutter:** Використовує канали платформи (platform channels), які є асинхронними та повільними для відеоданих з високою пропускною здатністю. Хоча FFI (Foreign Function Interface) покращує ситуацію, екосистема для прямої маніпуляції GPU-буферами є менш зрілою порівняно з нативними інструментами. Крім того, рендеринг Flutter на власному рушії Skia/Impeller може конфліктувати з нативними SurfaceView для відображення камери.
- **Нативна розробка (Kotlin/Swift):** Забезпечує прямий доступ "без копіювання" (zero-copy) до HardwareBuffer (Android) та CVPixelBuffer (iOS). Це дозволяє точно керувати плануванням потоків (Coroutines/GCD) для управління тепловим троттлінгом та зворотним тиском (backpressure), що є критичним для підтримки стабільного FPS при тривалому навантаженні.

**Вердикт: Проект використовуватиме підхід Native Core, Unified Interface.**

- **Ядро логіки (CV/ML):** Буде написано на оптимізованому Native (Kotlin для Android, Swift для iOS) або спільному C++ (через JNI/Objective-C++) для використання специфічних апаратних прискорювачів (CoreML на iOS, NNAPI/TFLite Delegate на Android).
- **UI шар:** Нативний декларативний UI (Jetpack Compose для Android, SwiftUI для iOS). Цей вибір забезпечує максимальну продуктивність рендерингу та глибоку інтеграцію з системними API камери, які часто відстають у крос-платформних обгортках.

### 2.3 Профілі Апаратного Прискорення
Для досягнення стандарту надійності "SpaceX", додаток повинен враховувати варіативність обладнання та використовувати спеціалізовані процесори.

- **Apple Neural Engine (ANE):** Оптимізований для CoreML. Ми повинні гарантувати, що моделі конвертовані у формат .mlpackage або запускаються через TFLite з увімкненим CoreML делегатом. Важливо використовувати квантування FP16, оскільки ANE працює з ним найбільш ефективно.
- **Android Neural Networks API (NNAPI) / Hexagon DSP:** Фрагментація Android вимагає надійного селектора делегатів. Ми будемо пріоритизувати GPU делегат для загальної сумісності, але реалізуємо відкат (fallback) до NPU (через NNAPI або QNN для чіпсетів Qualcomm) для мінімізації енергоспоживання. Тести показують, що використання NPU може знизити споживання енергії у 3.5-8.9 разів порівняно з CPU/GPU.

## 3. Комп'ютерний Зір та Машинне Навчання: Фундаментальний Рушій

### 3.1 Вибір Моделі: Арена Оцінки Пози
Основою стартапу є розуміння рухів людини. Ми провели аналіз SOTA (State-of-the-Art) моделей, доступних у 2025 році, базуючись на точності (mAP), затримці (ms) та часовій стабільності (jitter).

#### 3.1.1 Порівняльний Аналіз Кандидатів

| Модель | Архітектура | Латентність (Pixel 6) | Переваги | Недоліки |
| --- | --- | --- | --- | --- |
| MediaPipe Pose (BlazePose) | Encoder-Decoder / Heatmap | ~7ms (Lite) / 30ms (Full) | 33 ключові точки, метрична 3D глибина, топологія включає обличчя/руки, оптимізовано для мобільних. | За замовчуванням трекінг однієї особи. |
| MoveNet (Google) | CenterNet-based | ~5ms (Lightning) | Надзвичайно швидка. | Високий рівень "тремтіння" (jitter), менш точна 3D глибина, низька точність при оклюзіях. |
| YOLOv8/11 Pose | YOLO (One-stage) | ~15-40ms | Відмінна детекція багатьох осіб, надійна історія об'єктної детекції. | Більше споживання ресурсів, переважно 2D вихідні дані. |
| OpenPose | Bottom-Up | >100ms | Висока точність для натовпу. | Занадто повільна для мобільного edge (вбивця батареї). |

**Стратегічний Вибір: MediaPipe Pose (BlazePose) обрано як основний рушій.**

Обґрунтування: Архітектура MediaPipe використовує складну схему "Детектор-Трекер". Вона детектує користувача лише один раз (у першому кадрі), а потім відстежує орієнтири від кадру до кадру, використовуючи легку регресійну модель на основі області інтересу (ROI). Це значно ефективніше, ніж запуск важкого детектора на кожному кадрі (як це робить YOLO). Крім того, вона надає 3D світові координати (метричний масштаб), що є критично важливим для аналізу техніки вправ або кінематики, дозволяючи вимірювати кути суглобів у реальному просторі, а не лише в проекції екрана.

### 3.2 Архітектура ML-Конвеєра (Pipeline)
ML-конвеєр не буде "чорною скринькою". Це модульна, спостережувана система, розроблена для логічного висновку "Ланцюг Дій" (Chain-of-Action).

#### 3.2.1 Двоступеневий Конвеєр
- **Холодний Старт (Детекція):** Повнокадровий детектор (BlazePose Detector) сканує зображення для пошуку людини. Він прогнозує обмежувальну рамку (bounding box) та грубе вирівнювання, а також визначає наявність людини в кадрі.
- **Швидкий Шлях (Трекінг):** Система обрізає область інтересу (ROI) на основі орієнтирів з попереднього кадру. Цей обрізаний тензор (зазвичай 256x256 пікселів) подається на модель регресії орієнтирів (Landmark Model). Це економить обчислювальні ресурси, оскільки модель працює з меншим зображенням.
- **Логіка Відновлення:** Якщо впевненість трекінгу падає нижче порогу min_tracking_confidence (наприклад, 0.5), система запускає петлю гістерезису і знову активує важкий детектор. Це запобігає "дрейфу" трекера, коли модель починає відстежувати фон замість людини.

#### 3.2.2 Стратегія Квантування
Щоб емулювати ефективність "Tesla", ми не можемо постачати роздуті FP32 (32-бітні float) моделі. Ми будемо використовувати Квантування після тренування (Post-Training Quantization) або Навчання з урахуванням квантування (Quantization Aware Training).

- **FP16 (Half-Precision):** Зменшує розмір моделі на 50% з майже нульовою втратою точності. Це кращий вибір для GPU делегатів, оскільки сучасні мобільні GPU нативно підтримують FP16 обчислення, що дає прискорення до 2 разів.
- **Int8 (Full Integer):** Зменшує розмір на 75% і дозволяє використовувати NPU/DSP. Це вимагає "Репрезентативного набору даних" (Representative Dataset) для калібрування, щоб відобразити динамічні діапазони float у цілі числа. Ми згенеруємо цей набір даних з наших власних різноманітних даних захоплення руху, щоб запобігти деградації точності в граничних випадках (наприклад, екстремальні кути йоги).

### 3.3 Кастомізація та Перенавчання
Хоча MediaPipe є базою, стиль SpaceX передбачає, що ми не покладаємося виключно на готові компоненти, якщо вони обмежують продуктивність. Ми впровадимо конвеєр перенавчання, використовуючи MediaPipe Model Maker.

- **Трансферне Навчання (Transfer Learning):** Ми донавчимо (fine-tune) бекбон BlazePose на пропрієтарному наборі даних специфічних рухів (наприклад, олімпійська важка атлетика або фізіотерапевтичні вправи). Це критично для покращення точності координати z (глибини), яка часто є найслабшим місцем моделей 2D-to-3D.
- **Headless Models (Моделі без голови):** Для доменів з підвищеними вимогами до приватності ми дослідимо можливість перенавчання моделі для виведення лише орієнтирів тіла, відкидаючи сітку обличчя (Face Mesh), або суворо фільтруватимемо вихідний тензор, щоб відкинути орієнтири обличчя ще до того, як вони покинуть захищений анклав пам'яті. Це технічна гарантія анонімності.

## 4. Архітектура Мобільної Системи

### 4.1 Архітектурний Патерн: Clean Architecture + MVI
Для забезпечення масштабованості та тестованості додаток буде суворо дотримуватися принципів Чистої Архітектури (Clean Architecture), адаптованих для мобільної розробки (Android/iOS). Це відокремлює бізнес-логіку (Сутності) від деталей фреймворку (UI, База даних, Сенсори).

#### 4.1.1 Розподіл Шарів
- **Domain Layer (Pure Kotlin/Swift):** Це серце системи.
  - **Entities (Сутності):** Pose, Landmark, RepetitionCounter. Ці класи не повинні мати жодних залежностей від Android SDK або UIKit.
  - **Use Cases (Варіанти використання):** AnalyzeSquatUseCase, DetectFallUseCase. Вони інкапсулюють специфічну бізнес-логіку.
  - **Interfaces:** Визначення репозиторіїв (PoseRepository).
- **Data Layer (Infrastructure):**
  - **Repositories:** Реалізація інтерфейсів домену.
  - **Data Sources:** CameraDataSource (керує CameraX/AVFoundation), MLModelDataSource (обгортка над MediaPipe).
- **Presentation Layer:**
  - **State Management:** Model-View-Intent (MVI). MVI обрано замість MVVM через його суворий односпрямований потік даних. У реальному часі, коли стан змінюється 30 разів на секунду, можливість відтворити послідовність станів є критичною для налагодження.
  - **UI:** Jetpack Compose / SwiftUI. UI є лише функцією стану: UI = f(State).

### 4.2 Конвеєр Обробки Відео
Обробка відео в реальному часі — це задача системної інженерії. Конвеєр повинен обробляти Зворотний Тиск (Backpressure) — ситуацію, коли камера генерує кадри швидше, ніж ML-модель може їх обробити.

**Реалізація Конвеєра Android:**

- **Джерело:** CameraX з використанням ImageAnalysis.Builder.
- **Стратегія:** STRATEGY_KEEP_ONLY_LATEST. Ми повинні негайно відкидати старі кадри. Обробка кадру, якому вже 500 мс, є марною тратою ресурсів у системі реального часу.
- **Паралелізм:** Kotlin Coroutines з Flow.
  - Камера випромінює кадри в SharedFlow або Channel.
  - Споживач ML працює на Dispatchers.Default (інтенсивні обчислення) або спеціальному ExecutorService, прив'язаному до NPU делегата.
- **Обробка Backpressure:** Використовуйте .conflate() на потоці (flow), щоб відкидати проміжні значення, якщо колектор (ML модель) повільний, або оператор onBackpressureDrop() у концепціях RxJava.

**Реалізація Конвеєра iOS:**

- **Джерело:** AVCaptureVideoDataOutput.
- **Паралелізм:** Grand Central Dispatch (GCD) або Swift Concurrency (async/await).
- **Управління Буфером:** Прямий доступ до CMSampleBuffer. Ми повинні проактивно керувати пулом пам'яті, щоб запобігти "тепловому обриву" (thermal cliff), коли iPhone зменшує яскравість екрану та троттлить CPU після 5 хвилин інтенсивного використання ML.

### 4.3 Визначення Чистого Інтерфейсу
Щоб дозволити заміну ML-бекендів (наприклад, перехід з MediaPipe на кастомний Transformer у майбутньому), ми визначаємо суворий контракт, що відповідає Принципу Інверсії Залежностей (Dependency Inversion Principle):

```kotlin
interface PoseDetector {
    suspend fun detect(frame: Frame): Result<Pose>
    fun close()
}

data class Pose(
    val landmarks: List<Landmark3D>,
    val timestamp: Long,
    val confidence: Float
)
```

Шар UI взаємодіє лише з PoseDetector, не знаючи, чи працює під капотом MediaPipe, MoveNet, чи мок-об'єкт для тестування.

## 5. Структура Репозиторію та Управління

### 5.1 Монорепозиторій (Monorepo) vs. Полірепозиторій
Для стартапу, що прагне високої швидкості (velocity), Монорепозиторій є кращим вибором. Він дозволяє атомарні коміти (зміна ML моделі та коду UI, що її споживає, в одному PR) та уніфікований інструментарій. Це відповідає філософії вертикальної інтеграції SpaceX.

**Запропонована Структура Директорій:**

```
/
├── .github/workflows/       # CI/CD Actions ("Фабрика")
├── apps/
│   ├── android-app/         # Нативний Android (Kotlin + Gradle)
│   ├── ios-app/             # Нативний iOS (Swift + Xcode)
│   └── web-dashboard/       # Адмінка/Аналітика (Next.js/React)
├── packages/                # Спільна логіка (якщо використовується KMP або C++ Core)
│   ├── core-ml/             # C++ MediaPipe graphs / TFLite моделі
│   └── domain-logic/        # Спільні бізнес-правила (можливо Kotlin Multiplatform)
├── ml-ops/                  # Середовище дослідження ML (Research Environment)
│   ├── data/                # DVC tracked data pointers (.dvc файли)
│   ├── models/              # Реєстр артефактів моделей
│   ├── notebooks/           # Jupyter notebooks для експериментів
│   └── src/                 # Python скрипти для тренування/евалюації
├── tools/                   # Скрипти для автоматизації, лінтери, Docker-файли
├── DVC.yaml                 # Конвеєр Data Version Control
└── README.md
```

### 5.2 Контроль Версій Даних (DVC)
Git призначений для коду; DVC — для даних та моделей. Ми будемо суворо використовувати DVC (Data Version Control) замість Git LFS.

**Обґрунтування:** DVC є агностичним до сховища (працює з S3, GDrive, Azure, SSH) і керує ML-конвеєрами (DAGs). Він дозволяє версіонувати експеримент (дані + код + гіперпараметри) разом. Git LFS є жорстким, залежним від сервера і часто дорогим на GitHub.

**Робочий процес:** Великі .tflite моделі та набори даних для тренування залишаються в об'єктному сховищі (S3). У Git комітяться лише DVC-файли (model.tflite.dvc), які містять хеші. Розробники виконують dvc pull, щоб отримати бінарні активи.

### 5.3 Стратегія Гілкування та Комітів
- **Стратегія:** Trunk-Based Development. Довгоживучі гілки фіч (feature branches) заборонені. Код зливається в main щодня, прихований за Feature Flags. Це зменшує пекло злиття (merge hell) і змушує писати модульний код.
- **Стиль Комітів:** Conventional Commits (feat: add squat logic, fix: memory leak in camera). Це дозволяє автоматично генерувати changelog та керувати семантичним версіонуванням.

## 6. MLOps та Автоматизація CI/CD

### 6.1 Конвеєр CI/CD (GitHub Actions)
Стиль SpaceX вимагає, щоб кожен коміт був протестований, зібраний і потенційно готовий до розгортання. Ми будемо використовувати GitHub Actions, оркестровані з Fastlane для мобільної доставки.

**Визначення Робочого Процесу (Workflow):**

- **Тригер:** on: push в main або pull_request.
- **Шлюз Якості (Quality Gate):**
  - **Лінтинг:** ktlint (Android), SwiftLint (iOS), Black/Ruff (Python). Код, який не відповідає стандарту стилю, автоматично відхиляється.
  - **Unit Tests:** JUnit/XCTest для бізнес-логіки.
  - **ML Validation Gate (Шлюз Валідації ML):**
    - Перед компіляцією додатку конвеєр перевіряє, чи змінилася ML-модель.
    - Якщо модель змінена, запускається скрипт model-eval (Python) проти валідаційного набору даних ("Golden Dataset").
    - **Умова провалу:** Якщо точність (mAP) впала більше ніж на 1%, або розмір моделі зріс без обґрунтування, білд падає. Це запобігає "тихим збоям", коли оптимізація розміру вбиває точність.
- **Збірка та Розподіл:**
  - **Android:** Збірка AAB -> Завантаження в Firebase App Distribution (Internal).
  - **iOS:** Збірка IPA -> Завантаження в TestFlight (Internal).
- **Fastlane:** Керує сертифікатами підпису (Match), інкрементом версій та завантаженням.

### 6.2 Автоматизоване Тестування Продуктивності на Пристрої
Симуляція ML на сервері недостатня; продуктивність залежить від теплового стану пристрою.

- **Ферма Пристроїв:** Ми інтегруємо крок запуску ML-моделі на реальних пристроях (використовуючи Firebase Test Lab або AWS Device Farm).
- **Бенчмаркінг:** CI-конвеєр вимірюватиме час інференсу та споживання енергії. Якщо нова версія моделі збільшує час інференсу більше ніж на 10% на еталонному пристрої (наприклад, Pixel 6), пул-реквест блокується.

## 7. Приватність Даних, Безпека та Комплаєнс (GDPR/AI Act)

### 7.1 Обробка Тільки Скелета (Skeleton-Only)
Щоб відповідати EU AI Act та GDPR (Стаття 9 про біометрію), ми приймаємо архітектуру Privacy-by-Design.

- **Сире Відео:** Ніколи не покидає оперативну пам'ять пристрою. Воно перезаписується з кожним новим кадром.
- **Передача:** Якщо хмарна аналітика необхідна, передаються лише витягнуті метадані (33 числових вектори орієнтирів: x, y, z).
- **Анонімізація:** Орієнтири обличчя (індекси 0-10 у MediaPipe) програмно видаляються або зануляються перед будь-яким збереженням даних, якщо вони не є критично необхідними для функції (наприклад, аналіз нахилу голови). Це ефективно "обезголовлює" дані з точки зору приватності, роблячи ідентифікацію особи майже неможливою.

### 7.2 Захищені Анклави
Файли ML-моделей є інтелектуальною власністю. Вони будуть зашифровані в стані спокою (at rest) всередині пакету мобільного додатку, щоб запобігти крадіжці (екстракції моделі). Ключі шифрування керуються через Android Keystore / iOS Keychain.

## 8. Регламент Впровадження (Інструкція до Дії)
Цей розділ діє як прямий набір інструкцій, який необхідно додати до файлу CONTRIBUTING.md або ENGINEERING_HANDBOOK.md у репозиторії.

### 8.1 Критичний Протокол: Правило "Без Привидів"
**Правило:** Жодна логіка не існує без тесту. Жодна модель не існує без бенчмарку.

**Впровадження:** Кожен Pull Request (PR), що стосується логіки ML, повинен містити скріншот або лог виводу тесту LatencyBenchmark, запущеного на фізичному пристрої.

### 8.2 Протокол: Стандарт Інтеграції Моделей
При додаванні нової моделі .tflite або .mlmodel:

1. Додайте вихідний файл у ml-ops/models/.
2. Виконайте dvc add ml-ops/models/new_model.tflite.
3. Закомітьте файл .dvc у Git.
4. Оновіть файл model_card.md, пояснюючи походження моделі, метрики точності та призначення.
5. Оновіть Constants.kt / Constants.swift для посилання на новий шлях до моделі.

### 8.3 Протокол: Бар'єр 16мс
Потік UI ніколи не повинен блокуватися.

- **Android:** Використовуйте suspend функції для всіх взаємодій з ML. Використовуйте withContext(Dispatchers.Default) для попередньої обробки тензорів.
- **iOS:** Виконуйте всі запити Vision у фоновому DispatchQueue або Task. Оновлюйте UI тільки на MainActor.

**Порушення:** Будь-який лог про пропущений кадр (dropped frame) у профайлері запускає обов'язковий рефакторинг.

### 8.4 Покрокова Дорожня Карта Впровадження

**Фаза 1: Риштування (Тижні 1-2)**
- Ініціалізувати Монорепозиторій зі стандартною структурою директорій.
- Налаштувати DVC з бакетом S3/GCS для віддаленого зберігання.
- Налаштувати CI/CD: GitHub Actions + Fastlane для розгортання додатку "Hello World" внутрішнім тестувальникам.

**Фаза 2: Око (Тижні 3-6)**
- Реалізувати базові конвеєри CameraX (Android) та AVFoundation (iOS) з акцентом на буфери аналізу зображень.
- Інтегрувати бібліотеку MediaPipe Tasks Vision.
- Реалізувати утиліту "Нормалізація Координат" (перетворення нормалізованих координат 0-1 у піксельні координати).
- Побудувати інтерфейс PoseDetector та його реалізацію на MediaPipe.

**Фаза 3: Мозок (Тижні 7-10)**
- Розробити логіку "Лічильника Повторень" у шарі Domain (чиста математика, без залежностей від фреймворку).
- Впровадити "Згладжуючі Фільтри" (наприклад, OneEuroFilter) для зменшення тремтіння орієнтирів.
- Підключити UI до кінцевого автомата (State Machine) MVI.

**Фаза 4: Оптимізація (Тижні 11+)**
- Профілювати використання енергії.
- Впровадити делегати NPU.
- Видалити невикористовувані ресурси ("Delete the Part").

## 9. Висновок
Цей звіт надає проектний план для мобільного AI-стартапу світового класу. Дотримуючись ефективності в стилі "SpaceX" — нативного використання обладнання, чистої модульної архітектури та автоматизованих операцій — цей фундамент дозволяє команді зосередитися на інноваціях продукту, а не на боротьбі з технічним боргом. "Відповідальний Інженер" тепер повинен взяти ці протоколи та виконати їх зі швидкістю та точністю. Фундамент закладено; тепер ми будуємо.
