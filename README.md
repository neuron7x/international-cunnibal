# International Cunnibal

<div align="center">

# ğŸ§  International Cunnibal

## *Train, Dominate, Savor.*

<p align="center">
  <img src="https://img.shields.io/badge/Flutter-3.0+-02569B?style=for-the-badge&logo=flutter&logoColor=white"
       alt="Flutter" />
  <img src="https://img.shields.io/badge/TensorFlow_Lite-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white"
       alt="TFLite" />
  <img src="https://img.shields.io/badge/Dart-0175C2?style=for-the-badge&logo=dart&logoColor=white"
       alt="Dart" />
  <img src="https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge"
       alt="License" />
</p>

<p align="center">
  <img src="https://img.shields.io/badge/AI-On--Device-blueviolet?style=flat-square&logo=brain" alt="AI" />
  <img src="https://img.shields.io/badge/Privacy-First-success?style=flat-square&logo=shield" alt="Privacy" />
  <img src="https://img.shields.io/badge/Real--Time-30_FPS-orange?style=flat-square&logo=speedtest"
       alt="Real-Time" />
  <img src="https://img.shields.io/badge/Platform-Android%20%7C%20iOS-blue?style=flat-square&logo=mobile"
       alt="Platform" />
</p>

### ğŸš€ Neural Biofeedback Engine for Precision Oral Biomechanics

*Revolutionary sensory-motor synchronization training powered by Anokhin's Action Acceptor theory*

[ğŸ¯ Features](#-features) â€¢ [ğŸ“± Demo](#-demo) â€¢ [ğŸ› ï¸ Quick Start](#-installation) â€¢
[ğŸ“Š Architecture](#-architecture) â€¢ [ğŸ§­ Delivery Plan](docs/delivery_plan.md) â€¢ [ğŸ¤ Contributing](#-contributing)

---

</div>

## ğŸŒŸ Overview

**International Cunnibal** is a cutting-edge Flutter application that brings neuroscience to your fingertips.
Built on **Anokhin's Action Acceptor theory**, this sophisticated neural biofeedback system provides real-time
tongue biomechanics tracking and analysis through advanced on-device AI processing.

<div align="center">

### ğŸ’¡ Why International Cunnibal?

</div>

<table>
<tr>
<td width="33%" align="center">
<img src="https://img.icons8.com/fluency/96/brain.png" width="64" alt="AI Brain"/><br/>
<b>ğŸ§  AI-Powered</b><br/>
Advanced neural engine with Action Acceptor validation
</td>
<td width="33%" align="center">
<img src="https://img.icons8.com/fluency/96/privacy.png" width="64" alt="Privacy"/><br/>
<b>ğŸ”’ Privacy First</b><br/>
100% on-device processing, zero cloud dependency
</td>
<td width="33%" align="center">
<img src="https://img.icons8.com/fluency/96/speed.png" width="64" alt="Speed"/><br/>
<b>âš¡ Real-Time</b><br/>
30 FPS tracking with instant feedback
</td>
</tr>
</table>

## âœ¨ Features

<div align="center">

### ğŸ¯ Core Capabilities

</div>

<details open>
<summary><b>ğŸ“¸ Bio-Tracking</b> - Real-time Tongue Biomechanics</summary>

<br/>

```mermaid
graph LR
    A[ğŸ“· Camera] -->|30 FPS| B[ğŸ§  AI Processing]
    B --> C[ğŸ“Š Landmarks]
    C --> D[âœ… Validation]
    D --> E[ğŸ“ˆ Metrics]
```

- âœ… **High-frequency camera tracking** at 30 FPS
- âœ… **MediaPipe/TFLite integration** for landmark detection
- âœ… **Velocity & acceleration** calculations in real-time
- âœ… **Action Acceptor validation** for movement consistency
- âœ… **10-point landmark** detection for precision tracking

</details>

<details open>
<summary><b>ğŸ“Š Biometric Metrics</b> - Advanced Performance Analytics</summary>

<br/>

| Metric | Description | Range |
|--------|-------------|-------|
| ğŸ¯ **Consistency Score** | Standard deviation-based measurement | 0-100% |
| ğŸ”„ **Frequency Analysis** | Movement frequency tracking | Hz |
| ğŸ“ **Vector PCA** | Principal Component Analysis | PC1, PC2, PC3 |

**Real-time updates** â€¢ **Statistical analysis** â€¢ **Pattern recognition**

</details>

<details open>
<summary><b>ğŸ§­ Facial Endurance Training</b> - Jaw Endurance, Stability, Control</summary>

<br/>

- Optional, consent-based jaw endurance sessions for comfort and control
- On-device aperture tracking with objective, bounded metrics
- Session flow with ready â†’ hold â†’ rest â†’ summary and safety auto-pauses
- No rankings or public comparisons by default

</details>

<details open>
<summary><b>ğŸ”¤ Symbol Dictation (A-Z)</b> - Rhythmic Synchronization</summary>

<br/>

Partner-led training with **26 unique rhythm patterns** inspired by Morse code:

```text
A: .-    (Short-Long)
B: -...  (Long-Short-Short-Short)
S: ...   (Short-Short-Short)
```

- ğŸµ **Real-time synchronization** scoring
- ğŸ“ˆ **Rhythm consistency** analysis
- ğŸ¨ **Interactive symbol** selection interface
- â±ï¸ **Timing precision** validation (0.2s short, 0.6s long)

</details>

<details open>
<summary><b>ğŸ¤ Partner Mode</b> - Set the Rhythm Together</summary>

<br/>

- ğŸ‘« Partner taps out a custom short/long pattern
- ğŸ¯ You mirror the rhythm with tongue movements in real time
- ğŸ”„ Live synchronization and stability scores
- ğŸ”’ 100% on-device processing â€” no uploads, no streaming

</details>

<details open>
<summary><b>ğŸ” Infrastructure</b> - Privacy-Focused Architecture</summary>

<br/>

<table>
<tr>
<td align="center">ğŸ”’</td>
<td><b>On-Device AI</b><br/>All processing happens locally using TFLite</td>
</tr>
<tr>
<td align="center">ğŸ“¤</td>
<td><b>Automated Exports</b><br/>JSON performance logs with timestamps</td>
</tr>
<tr>
<td align="center">ğŸ“</td>
<td><b>Session Logging</b><br/>Comprehensive tracking with summaries</td>
</tr>
<tr>
<td align="center">ğŸš«</td>
<td><b>No Cloud</b><br/>Zero external server communication</td>
</tr>
</table>

</details>

---

## ğŸ“± Demo

<div align="center">

### ğŸ¥ App Showcase

<table>
<tr>
<td width="33%" align="center">
<b>ğŸ  Home Screen</b><br/>
<sub>Feature navigation hub</sub><br/>
<img src="https://img.shields.io/badge/Status-Implemented-success?style=flat-square" />
</td>
<td width="33%" align="center">
<b>ğŸ“¸ Bio-Tracking</b><br/>
<sub>Real-time camera feed</sub><br/>
<img src="https://img.shields.io/badge/FPS-30-orange?style=flat-square" />
</td>
<td width="33%" align="center">
<b>ğŸ“Š Metrics</b><br/>
<sub>Live analytics dashboard</sub><br/>
<img src="https://img.shields.io/badge/Updates-1Hz-blue?style=flat-square" />
</td>
</tr>
</table>

### ğŸ¯ Key User Flows

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant A as ğŸ“± App
    participant C as ğŸ“· Camera
    participant N as ğŸ§  NeuralEngine

    U->>A: Open App
    A->>U: Show Home Screen
    U->>A: Start Bio-Tracking
    A->>C: Initialize Camera
    C->>N: Stream Frames (30 FPS)
    N->>N: Process & Validate
    N->>A: Send Metrics (1 Hz)
    A->>U: Display Results
```

</div>

---

## ğŸ—ï¸ Architecture

<div align="center">

### ğŸ¨ System Design

```mermaid
graph TB
    subgraph "ğŸ“± Presentation Layer"
        A[HomeScreen] --> B[TrackingScreen]
        A --> C[DictationScreen]
        A --> D[MetricsScreen]
    end

    subgraph "âš™ï¸ Business Logic"
        E[NeuralEngine] --> F[Action Acceptor]
        G[BioTrackingService] --> E
        H[SymbolDictationService] --> E
        I[GitHubExportService]
    end

    subgraph "ğŸ’¾ Data Layer"
        J[TongueData] --> E
        K[BiometricMetrics] --> I
        L[DictationSession] --> I
    end

    B --> G
    C --> H
    D --> I
    E --> K
```

</div>

### ğŸ§  NeuralEngine Service

**Anokhin's Action Acceptor Implementation** *(Reference: 2025-11-30)*

<table>
<tr>
<td width="25%" align="center">
<b>1ï¸âƒ£</b><br/>
ğŸ“¥ Accept<br/>
<sub>Sensory Input</sub>
</td>
<td width="25%" align="center">
<b>2ï¸âƒ£</b><br/>
ğŸ”„ Compare<br/>
<sub>Pattern Matching</sub>
</td>
<td width="25%" align="center">
<b>3ï¸âƒ£</b><br/>
âœ… Validate<br/>
<sub>Motor Execution</sub>
</td>
<td width="25%" align="center">
<b>4ï¸âƒ£</b><br/>
ğŸ“Š Feedback<br/>
<sub>Real-time Results</sub>
</td>
</tr>
</table>

- ğŸ”„ Processes **afferent (sensory)** input from tongue tracking
- ğŸ“Š Compares **actual movements** with expected patterns
- âœ… Validates **motor command** execution
- ğŸ’¡ Provides **real-time feedback** for sensory-motor learning

### ğŸ› ï¸ Core Services

<details>
<summary><b>ğŸ¬ BioTrackingService</b> - Camera & Detection</summary>

```dart
// Camera integration and biomechanics detection
- ğŸ“· 30 FPS camera processing
- ğŸ¯ Landmark detection (10 points)
- ğŸ“ˆ Velocity & acceleration tracking
- ğŸ”„ Real-time streaming to NeuralEngine

```

</details>

<details>
<summary><b>ğŸ”¤ SymbolDictationService</b> - Pattern Matching</summary>

```dart
// Rhythm pattern matching and synchronization
- ğŸµ 26 unique A-Z patterns (Morse-inspired)
- â±ï¸ Timing validation (0.2s/0.6s)
- ğŸ“Š Synchronization scoring (0-100%)
- ğŸ“ˆ Rhythm consistency analysis

```

</details>

<details>
<summary><b>ğŸ“¤ GitHubExportService</b> - Data Export</summary>

```dart
// Performance log generation and export
- ğŸ“ JSON format with timestamps
- ğŸ¤– Auto-export after 100 metrics
- ğŸ“Š Summary statistics included
- ğŸ’¾ Local storage only

```

</details>

### ğŸ“¦ Data Models

| Model | Purpose | Fields |
|-------|---------|--------|
| ğŸ¯ **TongueData** | Biomechanics tracking | Position, velocity, acceleration, landmarks, validation |
| ğŸ“Š **BiometricMetrics** | Performance analytics | Consistency, frequency, PCA variance |
| ğŸ”¤ **DictationSession** | Symbol training | Target symbol, timestamps, sync score, rhythm |

---

## ğŸ’» Technical Stack

<div align="center">

<table>
<tr>
<td align="center" width="96">
<img src="https://img.icons8.com/color/96/flutter.png" width="48" height="48" alt="Flutter" />
<br />Flutter 3.0+
</td>
<td align="center" width="96">
<img src="https://img.icons8.com/color/96/tensorflow.png" width="48" height="48" alt="TensorFlow" />
<br />TensorFlow Lite
</td>
<td align="center" width="96">
<img src="https://img.icons8.com/color/96/camera.png" width="48" height="48" alt="Camera" />
<br />MediaPipe
</td>
<td align="center" width="96">
<img src="https://img.icons8.com/color/96/dart.png" width="48" height="48" alt="Dart" />
<br />Dart 3.0+
</td>
<td align="center" width="96">
<img src="https://img.icons8.com/color/96/android-os.png" width="48" height="48" alt="Android" />
<br />Android 5.0+
</td>
<td align="center" width="96">
<img src="https://img.icons8.com/color/96/ios-logo.png" width="48" height="48" alt="iOS" />
<br />iOS 12+
</td>
</tr>
</table>

| Component | Technology | Purpose |
|-----------|-----------|---------|
| ğŸ¨ **Framework** | Flutter 3.0+ | Cross-platform mobile development |
| ğŸ¤– **AI/ML** | TensorFlow Lite | On-device model inference |
| ğŸ‘ï¸ **Vision** | MediaPipe | Landmark detection pipeline |
| ğŸ“· **Camera** | camera package | Real-time video capture |
| ğŸ’¾ **Storage** | path_provider | Local file management |
| ğŸ“Š **Export** | JSON | Performance log format |

</div>

---

## ğŸš€ Installation

<div align="center">

### Quick Start Guide

</div>

#### ğŸ“‹ Prerequisites

```bash
# Verify Flutter installation
flutter --version  # Flutter 3.0+

# Verify Dart installation
dart --version     # Dart 3.0+
```

#### ğŸ“¥ Clone & Setup

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/neuron7x/international-cunnibal.git

# 2ï¸âƒ£ Navigate to project directory
cd international-cunnibal

# 3ï¸âƒ£ Install dependencies
flutter pub get

# 4ï¸âƒ£ Run the app
flutter run

# Demo/simulation mode runs by default (no ML models needed)
# Quick logic loops:
# dart run tool/run_demo.dart
# dart run tool/verify_logic.dart
# dart run tool/benchmark_core.dart
```

#### ğŸ¯ Platform-Specific Setup

<details>
<summary><b>ğŸ¤– Android</b></summary>

```bash
# Check connected devices
flutter devices

# Run on Android device/emulator
flutter run -d android

# Build APK
flutter build apk --release
```

**Requirements:**

- Android SDK (API 21+)
- Android Studio (optional)
- USB Debugging enabled

</details>

<details>
<summary><b>ğŸ iOS</b></summary>

```bash
# Install iOS dependencies
cd ios && pod install && cd ..

# Run on iOS device/simulator
flutter run -d ios

# Build for iOS
flutter build ios --release
```

**Requirements:**

- macOS with Xcode 12+
- iOS 12.0+
- CocoaPods installed

</details>

---

## ğŸ“– Usage

<div align="center">

### ğŸ® User Guide

</div>

#### ğŸ“¸ Bio-Tracking Mode

```mermaid
flowchart LR
    A[ğŸ  Home] -->|Navigate| B[ğŸ“¸ Bio-Tracking]
    B -->|Grant| C[ğŸ“· Permissions]
    C -->|Tap| D[â–¶ï¸ START]
    D -->|Monitor| E[ğŸ“Š Live Data]
    E -->|Tap| F[â¹ï¸ STOP]
```

1. ğŸ  Navigate to **"Bio-Tracking"** from home screen
2. ğŸ“· **Grant camera permissions** when prompted
3. â–¶ï¸ Tap **"START TRACKING"** to begin real-time tracking
4. ğŸ‘€ View **live biomechanics data** and validation status
5. â¹ï¸ Tap **"STOP TRACKING"** when done

**Features Active:**

- âœ… Position tracking (x, y coordinates)
- âœ… Velocity calculation (pixels/second)
- âœ… Action Acceptor validation
- âœ… Real-time visual overlay

---

#### ğŸ”¤ Symbol Dictation Mode

```mermaid
flowchart LR
    A[ğŸ  Home] -->|Navigate| B[ğŸ”¤ Dictation]
    B -->|Select| C[ğŸ¯ Symbol A-Z]
    C -->|Tap| D[â–¶ï¸ START]
    D -->|Perform| E[ğŸµ Rhythm]
    E -->|Monitor| F[ğŸ“Š Score]
    F -->|Tap| G[â¹ï¸ STOP]
```

1. ğŸ  Navigate to **"Symbol Dictation"** from home screen
2. ğŸ¯ Select a **target symbol** (A-Z) from the grid
3. â–¶ï¸ Tap **"START DICTATION"**
4. ğŸµ Perform **rhythmic tongue movements** matching the symbol's pattern
5. ğŸ“Š Monitor **synchronization score** and rhythm consistency
6. â¹ï¸ Tap **"STOP DICTATION"** when done

**Pattern Examples:**

```text
A (.-):    Short-Long
S (...):   Short-Short-Short
T (-):     Long

```

---

#### ğŸ“Š Metrics Dashboard

```mermaid
flowchart LR
    A[ğŸ  Home] -->|Navigate| B[ğŸ“Š Dashboard]
    B -->|View| C[ğŸ“ˆ Metrics]
    C -->|Tap| D[ğŸ“¤ Export]
    D -->|Build| E[ğŸ§¾ JSON Payload]
```

1. ğŸ  Navigate to **"Metrics Dashboard"** from home screen
2. ğŸ“ˆ View **real-time biometric metrics**:
   - ğŸ¯ **Consistency Score** (based on std dev)
   - ğŸ”„ **Movement Frequency** (Hz)
   - ğŸ“ **Vector PCA** (principal components)
3. ğŸ“¤ Tap the **download icon** to export performance logs
4. ğŸ§¾ Export builds a **JSON payload** for sharing or manual saving

---

## ğŸ“Š Performance Logs

<div align="center">

### ğŸ“ Export Format

</div>

Exported logs include comprehensive data in **JSON format**:

```json
{
  "schemaVersion": 1,
  "exportedAtUtc": "2025-12-26T12:00:00.000Z",
  "appVersion": "1.0.0",
  "counts": {
    "metricsCount": 150,
    "sessionsCount": 12
  },
  "summary": {
    "metrics": {
      "consistencyScore": { "mean": 85.5, "min": 70.0, "max": 95.0 },
      "frequency": { "mean": 2.3, "min": 1.2, "max": 3.1 }
    },
    "sessions": {
      "meanSynchronization": 78.2,
      "minSynchronization": 60.0,
      "maxSynchronization": 92.0,
      "meanRhythmConsistency": 82.1
    }
  },
  "sessions": [
    {
      "targetSymbol": "A",
      "startTimeUtc": "2025-12-26T12:00:00Z",
      "durationSeconds": 1.0,
      "synchronizationScore": 78.2,
      "rhythmConsistency": 82.1
    }
  ]
}
```

---

## ğŸ“ Motion Metrics (Technical)

- **Consistency**: windowed motion-energy variance normalized by expected amplitude; bounded [0,100].
- **Frequency**: Hann-windowed autocorrelation, reports dominant Hz plus confidence (0-1);
  low-variance signals -> confidence 0.
- **Direction**: principal component of displacement covariance with deterministic orientation;
  stability = Î»max/trace on [0,100].
- **Intensity**: normalized mean kinetic proxy `E/(E+1)` on [0,100].
- **Pattern Match**: time-indexed vector-field MSE scaled by tolerance; score on [0,100].

## ğŸ‘©â€ğŸ“ Metrics Primer (Non-Technical)

- Consistency: how steady the motion energy is.
- Frequency: main rhythm (beats per second) plus confidence.
- Direction: dominant axis of movement.
- Intensity: how strong the motion is relative to expected range.
- Pattern Match: closeness to a target rhythm/path.

## ğŸ›  CLI Scripts (no ML needed)

```bash
dart run tool/run_demo.dart        # streams demo engine + prints metrics
dart run tool/verify_logic.dart    # runs metrics -> game logic ingestion
dart run tool/benchmark_core.dart  # benchmarks MotionMetrics core
```

Benchmark note: MotionMetrics processes a 30â€¯FPS window in well under 1â€¯ms on a mid-range device (see tool output).

#### ğŸ¯ What's Included

| Section | Content |
|---------|---------|
| â° **Timestamp** | Export date and time |
| ğŸ“± **App Version** | Version identifier |
| ğŸ“Š **Metrics** | Aggregated biometric ranges (mean/min/max) |
| ğŸ”¤ **Sessions** | Session summaries only (no raw timestamps) |
| ğŸ“ˆ **Summary** | Aggregated statistics and counts |

---

## ğŸ“š References

<div align="center">

### ğŸ”¬ Scientific Foundation

</div>

<table>
<tr>
<td width="50%">

**ğŸ“– Theoretical Framework**

- ğŸ§  Anokhin's Action Acceptor theory
- ğŸ“… Reference date: 2025-11-30
- ğŸ¯ Sensory-motor validation system
- âœ… Afferent signal comparison

</td>
<td width="50%">

**ğŸ”§ Technical Implementation**

- ğŸ“¸ MediaPipe/TFLite integration
- ğŸ“Š Metrics calculation methods
- ğŸ”’ On-device AI processing
- ğŸ“¤ Automated log exports

</td>
</tr>
</table>

#### ğŸ“ Key Citations

1. **Anokhin's Action Acceptor Theory** *(2025-11-30)*
   - Foundation for sensory-motor validation

2. **Real-time Tongue Biomechanics via MediaPipe/TFLite** *(2025-11-30)*
   - Computer vision and AI integration

3. **Metrics: Consistency Score (Std Dev), Frequency (Hz), Vector PCA** *(2025-11-30)*
   - Statistical analysis methods

4. **On-device AI for Privacy & Automated GitHub Performance Log Exports** *(2025-11-30)*
   - Privacy-first architecture and data management

---

## ğŸ”’ Privacy

<div align="center">

### ğŸ›¡ï¸ Privacy-First Architecture

<img src="https://img.shields.io/badge/ğŸ”_Privacy-100%25_On--Device-success?style=for-the-badge" alt="Privacy" />

</div>

All processing happens **on-device**. Your data never leaves your phone.

<table>
<tr>
<td align="center" width="25%">
<img src="https://img.icons8.com/fluency/96/lock.png" width="64" alt="Lock"/><br/>
<b>ğŸ”’ Zero Cloud</b><br/>
<sub>No external servers</sub>
</td>
<td align="center" width="25%">
<img src="https://img.icons8.com/fluency/96/processor.png" width="64" alt="Processor"/><br/>
<b>ğŸ“± Local Processing</b><br/>
<sub>On-device AI only</sub>
</td>
<td align="center" width="25%">
<img src="https://img.icons8.com/fluency/96/database.png" width="64" alt="Database"/><br/>
<b>ğŸ’¾ Local Storage</b><br/>
<sub>Data stays on device</sub>
</td>
<td align="center" width="25%">
<img src="https://img.icons8.com/fluency/96/no-network.png" width="64" alt="No Network"/><br/>
<b>ğŸš« No Internet</b><br/>
<sub>Works offline</sub>
</td>
</tr>
</table>

#### âœ… Privacy Guarantees

- âœ… **Local TFLite models** for AI inference
- âœ… **Local storage** for performance logs
- âœ… **No network connectivity** required for core functionality
- âœ… **No data collection** or analytics
- âœ… **No third-party services** or SDKs
- âœ… **User-controlled exports** only

#### ğŸ” Data Security

```mermaid
graph LR
    A[ğŸ“· Camera] -->|Local Only| B[ğŸ§  AI Processing]
    B -->|On Device| C[ğŸ“Š Metrics]
    C -->|User Export| D[ğŸ’¾ Local File]

    style A fill:#90EE90
    style B fill:#90EE90
    style C fill:#90EE90
    style D fill:#90EE90
```

---

## ğŸ“„ License

<div align="center">

### MIT License

<img src="https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge" alt="License" />

Copyright Â© 2025 **International Cunnibal Project**

```text
Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, subject to the following conditions...
```

See [LICENSE](LICENSE) file for full details.

</div>

---

<div align="center">

## ğŸŒŸ Star Us

If you find this project useful, please consider giving it a â­

### ğŸ“¬ Contact & Support

<a href="https://github.com/neuron7x/international-cunnibal/issues">
<img src="https://img.shields.io/badge/Report-Issues-red?style=for-the-badge&logo=github" alt="Issues" />
</a>
<a href="https://github.com/neuron7x/international-cunnibal/discussions">
<img src="https://img.shields.io/badge/Join-Discussions-blue?style=for-the-badge&logo=github" alt="Discussions" />
</a>

### ğŸ“š Documentation

[ğŸ“– Architecture](ARCHITECTURE.md) â€¢ [ğŸ”§ API Reference](API.md) â€¢ [ğŸš€ Quick Start](QUICKSTART.md) â€¢ [ğŸ’¡ Implementation](IMPLEMENTATION.md)

---

<p align="center">
<b>International Cunnibal</b><br/>
<i>Train, Dominate, Savor. ğŸ¯</i><br/><br/>
Made with â¤ï¸ using Flutter & TensorFlow Lite
</p>

<p align="center">
<img src="https://img.shields.io/badge/Built_with-Flutter-02569B?logo=flutter" alt="Flutter" />
<img src="https://img.shields.io/badge/Powered_by-TensorFlow_Lite-FF6F00?logo=tensorflow" alt="TFLite" />
<img src="https://img.shields.io/badge/Privacy-First-success?logo=shield" alt="Privacy" />
</p>

</div>

## ğŸ”’ Security & CI pipeline

See [SECURITY_PIPELINE.md](SECURITY_PIPELINE.md) for the mandatory gates
(CI, security scanning, doc/metric guardrails, and branch protection expectations) that every PR must satisfy.

## ğŸ¤ Contributing

<div align="center">

### ğŸ’« Join Our Community

<img src="https://img.shields.io/badge/Contributions-Welcome-brightgreen?style=for-the-badge" alt="Contributions" />
<img src="https://img.shields.io/badge/PRs-Accepted-blue?style=for-the-badge" alt="PRs" />
<img src="https://img.shields.io/badge/Issues-Open-orange?style=for-the-badge" alt="Issues" />

</div>

We follow clean code principles and Flutter best practices. All contributions should maintain:

<table>
<tr>
<td align="center">
âœ…<br/><b>Clean Code</b><br/>
<sub>Clear separation of concerns</sub>
</td>
<td align="center">
ğŸ“<br/><b>Documentation</b><br/>
<sub>Comprehensive comments</sub>
</td>
<td align="center">
ğŸ”’<br/><b>Type Safety</b><br/>
<sub>Null-safe Dart code</sub>
</td>
<td align="center">
ğŸ›¡ï¸<br/><b>Privacy First</b><br/>
<sub>On-device processing</sub>
</td>
</tr>
</table>

#### ğŸš€ Quick Contribution Guide

```bash
# 1ï¸âƒ£ Fork the repository
# 2ï¸âƒ£ Clone your fork
git clone https://github.com/YOUR_USERNAME/international-cunnibal.git

# 3ï¸âƒ£ Create a feature branch
git checkout -b feature/amazing-feature

# 4ï¸âƒ£ Make your changes
# ... code, test, document ...

# 5ï¸âƒ£ Commit your changes
git commit -m "âœ¨ Add amazing feature"

# 6ï¸âƒ£ Push to your fork
git push origin feature/amazing-feature

# 7ï¸âƒ£ Open a Pull Request
```

#### ğŸ“‹ Contribution Guidelines

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines on:

- ğŸ’» Code style and standards
- ğŸ§ª Testing requirements
- ğŸ“ Documentation standards
- ğŸ”„ PR submission process

---
